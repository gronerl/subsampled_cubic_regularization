{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, datasets\n",
    "import os\n",
    "import simplejson\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "import loss_functions, make_plots\n",
    "import scr, tr, gradient_methods, saga    \n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) load data and initialize weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset a9a loaded\n",
      "n = 32561 d = 123\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "#### Load  Data  ####\n",
    "#####################\n",
    "\n",
    "dataset_name='a9a' \n",
    "\n",
    "#logistic regression:\n",
    "if dataset_name=='a9a':\n",
    "    X, Y = load_svmlight_file('data/a9a')\n",
    "    X = X.toarray()\n",
    "    Y= [0 if e == -1 else e for e in Y]\n",
    "    Y=np.array(Y)      \n",
    "    d = X.shape[1]\n",
    "    n = X.shape[0]\n",
    "    w = np.zeros(d)\n",
    "    \n",
    "#multinominal (softmax) regression:\n",
    "elif dataset_name == 'mnist':\n",
    "    import scipy \n",
    "    X, Y = load_svmlight_file('data/mnist')\n",
    "    X = X.toarray()\n",
    "    nC = len(np.unique(Y))    \n",
    "    ## one-hot encoding of labels\n",
    "    data   = np.ones(len(Y))\n",
    "    indptr = np.arange(len(Y)+1)\n",
    "    ground_truth = scipy.sparse.csr_matrix((data, Y, indptr))\n",
    "    Y = ground_truth.todense() #gives a matrix with [Ground_Truth]i,j: is sample i in class j? (n x nC)\n",
    "    d = X.shape[1]\n",
    "    n = X.shape[0]\n",
    "    w = np.zeros(nC*d)\n",
    "\n",
    "#general function    \n",
    "elif dataset_name=='rosenbrock':\n",
    "    d=2\n",
    "    n=1 \n",
    "    w = np.zeros(d)\n",
    "\n",
    "if not isinstance(X,torch.tensor._TensorBase):\n",
    "    X = torch.from_numpy(X)\n",
    "if not isinstance(Y,torch.tensor._TensorBase):\n",
    "    Y = torch.from_numpy(Y)\n",
    "if not isinstance(w,torch.tensor._TensorBase):\n",
    "    w = torch.from_numpy(w)\n",
    "\n",
    "print ('Dataset', dataset_name, 'loaded')    \n",
    "print ('n = ' + str(n) + ' d = ' + str(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) specify a loss, gradient, Hessian-vector-product and Hessian computations\n",
    "- (latter only needed for hard case)\n",
    "- functions need to have (w,X,Y,kwargs...) as input structure !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumPyWrapper:\n",
    "    def __init__(self,loss,gradient,Hv,Hessian,loss_args={}):\n",
    "        self.loss_numpy = loss\n",
    "        self.gradient_numpy = gradient\n",
    "        self.Hv_numpy = Hv\n",
    "        self.Hessian_numpy = Hessian\n",
    "        self.loss_args = loss_args\n",
    "        \n",
    "    def loss(self,w,X,Y,**kwargs):\n",
    "        return float(self.loss_numpy(w.numpy(),X.numpy(),Y.numpy(),**self.loss_args))\n",
    "    \n",
    "    def gradient(self,w,X,Y,**kwargs):\n",
    "        return torch.from_numpy(self.gradient_numpy(w.numpy(),X.numpy(),Y.numpy(),**self.loss_args))\n",
    "    \n",
    "    def Hv(self,w,X,Y,v,**kwargs):\n",
    "        return torch.from_numpy(self.Hv_numpy(w.numpy(),X.numpy(),Y.numpy(),v.numpy(),**self.loss_args))\n",
    "    \n",
    "    def Hessian(self,w,X,Y,**kwargs):\n",
    "        return torch.from_numpy(self.Hessian_numpy(w.numpy(),X.numpy(),Y.numpy(),**self.loss_args))\n",
    "    \n",
    "if dataset_name in {'a9a'}:\n",
    "    loss_computation_numpy = loss_functions.logistic_loss\n",
    "    gradient_computation_numpy = loss_functions.logistic_loss_gradient\n",
    "    hessian_vector_computation_numpy = loss_functions.logistic_loss_Hv\n",
    "    hessian_computation_numpy = loss_functions.logistic_loss_hessian\n",
    "        # Additional arguments that are to be passed to the Loss, Gradient, etc. computations\n",
    "    loss_args= {}\n",
    "    loss_args['alpha'] = 1e-3 # regularizer\n",
    "\n",
    "    wrapper = NumPyWrapper(\n",
    "        loss_computation_numpy,\n",
    "        gradient_computation_numpy,\n",
    "        hessian_vector_computation_numpy,\n",
    "        hessian_computation_numpy,\n",
    "        loss_args=loss_args)\n",
    "    loss_computation = wrapper.loss\n",
    "    gradient_computation = wrapper.gradient\n",
    "    hessian_vector_computation = wrapper.Hv\n",
    "    hessian_computation = wrapper.Hessian\n",
    "\n",
    "if dataset_name in {'mnist'}:\n",
    "    loss_computation = loss_functions.softmax_loss\n",
    "    gradient_computation = loss_functions.softmax_loss_gradient\n",
    "    hessian_vector_computation = loss_functions.softmax_loss_Hv\n",
    "    hessian_computation = loss_functions.softmax_loss_hessian\n",
    "    \n",
    "    loss_args= {}\n",
    "    loss_args['alpha'] = 1e-3\n",
    "    loss_args['n_classes'] = nC # for multiclass (softmax) regression\n",
    "    \n",
    "    wrapper = NumPyWrapper(\n",
    "        loss_computation_numpy,\n",
    "        gradient_computation_numpy,\n",
    "        hessian_vector_computation_numpy,\n",
    "        hessian_computation_numpy,\n",
    "        loss_args=loss_args)\n",
    "    loss_computation = wrapper.loss\n",
    "    gradient_computation = wrapper.gradient\n",
    "    hessian_vector_computation = wrapper.Hv\n",
    "    hessian_computation = wrapper.Hessian\n",
    "    \n",
    "\n",
    "    \n",
    "elif dataset_name == 'rosenbrock':\n",
    "    loss_computation_numpy = loss_functions.rosenbrock_loss\n",
    "    gradient_computation_numpy = loss_functions.rosenbrock_gradient\n",
    "    hessian_vector_computation_numpy = loss_functions.rosenbrock_Hv\n",
    "    hessian_computation_numpy = loss_functions.rosenbrock_hessian\n",
    "    \n",
    "    wrapper = NumPyWrapper(\n",
    "        loss_computation_numpy,\n",
    "        gradient_computation_numpy,\n",
    "        hessian_vector_computation_numpy,\n",
    "        hessian_computation_numpy)\n",
    "    loss_computation = wrapper.loss\n",
    "    gradient_computation = wrapper.gradient\n",
    "    hessian_vector_computation = wrapper.Hv\n",
    "    hessian_computation = wrapper.Hessian\n",
    "    \n",
    "    loss_args= {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plots(x_limits_time=None):\n",
    "    list_params=[]\n",
    "    list_loss=[]\n",
    "    list_x=[]\n",
    "    list_samples=[]\n",
    "    \n",
    "    log_scale=True\n",
    "    \n",
    "    over_time=True\n",
    "    over_iterations=True\n",
    "    over_epochs=True\n",
    "    \n",
    "    if SCR:\n",
    "        list_loss.append(SCR_loss)\n",
    "        list_x.append(SCR_x)\n",
    "        list_samples.append(SCR_samples)\n",
    "        list_params.append('SCR')\n",
    "        \n",
    "    if TR:\n",
    "        list_loss.append(TR_loss)\n",
    "        list_x.append(TR_x)\n",
    "        list_samples.append(TR_samples)\n",
    "        list_params.append('TR')\n",
    "        \n",
    "    if SGD:\n",
    "        list_loss.append(SGD_loss)\n",
    "        list_x.append(SGD_x)\n",
    "        list_samples.append(SGD_samples)\n",
    "        list_params.append('SGD')\n",
    "    if SAGA:\n",
    "        list_loss.append(SAGA_loss)\n",
    "        list_x.append(SAGA_x)\n",
    "        list_samples.append(SAGA_samples)\n",
    "        list_params.append('SAGA')\n",
    "        \n",
    "    if over_time:\n",
    "        make_plots.two_d_plot_time(list_loss,list_x,list_params,dataset_name, n, d, log_scale,x_limits=x_limits_time)\n",
    "        \n",
    "    if over_iterations:\n",
    "        make_plots.two_d_plot_iterations(list_loss,list_x,list_params,dataset_name, n, d, log_scale)\n",
    "        \n",
    "    if over_epochs:\n",
    "        make_plots.two_d_plot_epochs(list_loss,list_samples,list_params,dataset_name, n, d, log_scale)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Set parameters and run methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Subsampled Cubic Regularization ---\n",
      "\n",
      "cardinality of dataset n = 32561\n",
      "dimension of parameter space d = 123\n",
      "\n",
      "\n",
      "SCR configuration:\n",
      "\n",
      "* (outer) termination criteria \n",
      "   - max_iterations: 20\n",
      "   - grad_tol: 1e-09\n",
      "\n",
      "* trust region adaption parameters:\n",
      "   - initial_penalty: 0.01\n",
      "   - min_penalty: 0.0\n",
      "   - successful_threshold: 0.1\n",
      "   - very_successful_threshold: 0.9\n",
      "   - penalty_increase_multiplier: 2.0\n",
      "   - penalty_decrease_multiplier: 2.0\n",
      "   - accept_all_decreasing_steps: True\n",
      "\n",
      "* subsolver and related parameters:\n",
      "   - subproblem_solver: lanczos\n",
      "   - krylov_tol: 0.1\n",
      "   - exact_tol: 1e-07\n",
      "   - lanczos_termination_criterion: g\n",
      "   - solve_each_i_th_krylov_space: 1\n",
      "   - keep_Q_matrix_in_memory: True\n",
      "\n",
      "* trust region shape and related parameters:\n",
      "   - scaling_matrix:  uniform\n",
      "\n",
      "* sampling parameters:\n",
      "   - replacement: False\n",
      "   - sampling_scheme: independent\n",
      "   - Hessian_sampling_flag: True\n",
      "   - initial_sample_size_Hessian: 814\n",
      "   - gradient_sampling_flag: False\n",
      "   - loss_sampling_flag: False\n",
      "\n",
      "* sampling size scheme:\n",
      "   - sample_size_scheme: exponential\n",
      "   - exp_growth_constant: 1.6791331457613021\n",
      "\n",
      "* custom statistics collection:\n",
      "   - no custom statistics callback specified\n",
      "\n",
      "Lanczos converged after 2 iterations\n",
      "Iter 0: loss=0.42357674729929223334 ||g||=6.738e-01 time=2.254300e-02 dt=2.254e-02 penalty=5.000e-03\n",
      "        ||s||=1.054e+00 ||s||_M=1.054e+00 samples Hessian= 814 samples Gradient= 32561 samples loss= 32561\n",
      "        epoch=2.050e+00 rho=1.156637e+00 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Lanczos converged after 4 iterations\n",
      "Iter 1: loss=0.35673674851331038660 ||g||=1.595e-01 time=4.905000e-02 dt=2.651e-02 penalty=2.500e-03\n",
      "        ||s||=1.298e+00 ||s||_M=1.298e+00 samples Hessian= 814 samples Gradient= 32561 samples loss= 32561\n",
      "        epoch=4.100e+00 rho=1.233674e+00 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Lanczos converged after 5 iterations\n",
      "Iter 2: loss=0.33762088488103197959 ||g||=5.570e-02 time=7.706600e-02 dt=2.802e-02 penalty=1.250e-03\n",
      "        ||s||=1.183e+00 ||s||_M=1.183e+00 samples Hessian= 815 samples Gradient= 32561 samples loss= 32561\n",
      "        epoch=6.150e+00 rho=1.135592e+00 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Lanczos converged after 6 iterations\n",
      "Iter 3: loss=0.33380356609911054910 ||g||=1.704e-02 time=1.069120e-01 dt=2.985e-02 penalty=6.250e-04\n",
      "        ||s||=8.201e-01 ||s||_M=8.201e-01 samples Hessian= 817 samples Gradient= 32561 samples loss= 32561\n",
      "        epoch=8.200e+00 rho=1.067595e+00 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Lanczos converged after 10 iterations\n",
      "Iter 4: loss=0.33337540085016120761 ||g||=3.863e-03 time=1.431040e-01 dt=3.619e-02 penalty=6.250e-04\n",
      "        ||s||=5.100e-01 ||s||_M=5.100e-01 samples Hessian= 820 samples Gradient= 32561 samples loss= 32561\n",
      "        epoch=1.025e+01 rho=8.953808e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Lanczos converged after 12 iterations\n",
      "Iter 5: loss=0.33334457249836824122 ||g||=1.590e-03 time=1.833720e-01 dt=4.027e-02 penalty=6.250e-04\n",
      "        ||s||=1.315e-01 ||s||_M=1.315e-01 samples Hessian= 826 samples Gradient= 32561 samples loss= 32561\n",
      "        epoch=1.230e+01 rho=8.024934e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Lanczos converged after 15 iterations\n",
      "Iter 6: loss=0.33334136772995220932 ||g||=3.682e-04 time=2.327660e-01 dt=4.939e-02 penalty=6.250e-04\n",
      "        ||s||=4.524e-02 ||s||_M=4.524e-02 samples Hessian= 835 samples Gradient= 32561 samples loss= 32561\n",
      "        epoch=1.435e+01 rho=7.305977e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Lanczos converged after 15 iterations\n",
      "Iter 7: loss=0.33334081982481694739 ||g||=1.437e-04 time=2.816460e-01 dt=4.888e-02 penalty=6.250e-04\n",
      "        ||s||=1.495e-02 ||s||_M=1.495e-02 samples Hessian= 850 samples Gradient= 32561 samples loss= 32561\n",
      "        epoch=1.640e+01 rho=8.900248e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Lanczos converged after 17 iterations\n",
      "Iter 8: loss=0.33334076185668493064 ||g||=4.912e-05 time=3.293860e-01 dt=4.774e-02 penalty=6.250e-04\n",
      "        ||s||=5.360e-03 ||s||_M=5.360e-03 samples Hessian= 876 samples Gradient= 32561 samples loss= 32561\n",
      "        epoch=1.846e+01 rho=7.268657e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Lanczos converged after 16 iterations\n",
      "Iter 9: loss=0.33334075304385490934 ||g||=3.918e-05 time=3.709180e-01 dt=4.153e-02 penalty=6.250e-04\n",
      "        ||s||=2.074e-03 ||s||_M=2.074e-03 samples Hessian= 919 samples Gradient= 32561 samples loss= 32561\n",
      "        epoch=2.052e+01 rho=8.710450e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Lanczos converged after 19 iterations\n",
      "Iter 10: loss=0.33334075215662728464 ||g||=7.471e-06 time=4.160130e-01 dt=4.510e-02 penalty=6.250e-04\n",
      "         ||s||=7.260e-04 ||s||_M=7.260e-04 samples Hessian= 991 samples Gradient= 32561 samples loss= 32561\n",
      "         epoch=2.258e+01 rho=8.439198e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Lanczos converged after 21 iterations\n",
      "Iter 11: loss=0.33334075207558605536 ||g||=3.006e-06 time=4.717450e-01 dt=5.573e-02 penalty=6.250e-04\n",
      "         ||s||=2.315e-04 ||s||_M=2.315e-04 samples Hessian= 1112 samples Gradient= 32561 samples loss= 32561\n",
      "         epoch=2.464e+01 rho=8.977424e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Lanczos converged after 24 iterations\n",
      "Iter 12: loss=0.33334075206913527101 ||g||=6.767e-07 time=5.249320e-01 dt=5.319e-02 penalty=6.250e-04\n",
      "         ||s||=6.492e-05 ||s||_M=6.492e-05 samples Hessian= 1315 samples Gradient= 32561 samples loss= 32561\n",
      "         epoch=2.673e+01 rho=8.700692e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Lanczos converged after 29 iterations\n",
      "Iter 13: loss=0.33334075206873781116 ||g||=1.045e-07 time=5.944360e-01 dt=6.950e-02 penalty=3.125e-04\n",
      "         ||s||=1.545e-05 ||s||_M=1.545e-05 samples Hessian= 1656 samples Gradient= 32561 samples loss= 32561\n",
      "         epoch=2.883e+01 rho=9.546508e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Lanczos converged after 30 iterations\n",
      "Iter 14: loss=0.33334075206871727204 ||g||=2.336e-08 time=6.865960e-01 dt=9.216e-02 penalty=3.125e-04\n",
      "         ||s||=3.732e-06 ||s||_M=3.732e-06 samples Hessian= 2229 samples Gradient= 32561 samples loss= 32561\n",
      "         epoch=3.096e+01 rho=8.788940e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Lanczos converged after 30 iterations\n",
      "Iter 15: loss=0.33334075206871610630 ||g||=9.025e-09 time=7.747190e-01 dt=8.812e-02 penalty=1.563e-04\n",
      "         ||s||=8.239e-07 ||s||_M=8.239e-07 samples Hessian= 3191 samples Gradient= 32561 samples loss= 32561\n",
      "         epoch=3.316e+01 rho=9.719011e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Terminating due to gradient tolerance ( grad_norm = 9.356179929181363e-10 < 1e-09 )\n",
      "--- Trust Region ---\n",
      "\n",
      "cardinality of dataset n = 32561\n",
      "dimension of parameter space d = 123\n",
      "\n",
      "\n",
      "TR configuration:\n",
      "\n",
      "* (outer) termination criteria \n",
      "   - max_iterations: 20\n",
      "   - grad_tol: 1e-09\n",
      "\n",
      "* trust region adaption parameters:\n",
      "   - initial_trust_radius: 1.0\n",
      "   - max_trust_radius: inf\n",
      "   - successful_threshold: 0.1\n",
      "   - very_successful_threshold: 0.9\n",
      "   - radius_decrease_multiplier: 2.0\n",
      "   - radius_increase_multiplier: 2.0\n",
      "   - accept_all_decreasing_steps: True\n",
      "\n",
      "* subsolver and related parameters:\n",
      "   - subproblem_solver: GLTR\n",
      "   - krylov_tol: 0.1\n",
      "   - exact_tol: 1e-07\n",
      "\n",
      "* trust region shape and related parameters:\n",
      "   - scaling_matrix:  uniform\n",
      "\n",
      "* sampling parameters:\n",
      "   - replacement: False\n",
      "   - sampling_scheme: independent\n",
      "   - Hessian_sampling_flag: True\n",
      "   - initial_sample_size_Hessian: 814\n",
      "   - gradient_sampling_flag: False\n",
      "   - loss_sampling_flag: False\n",
      "\n",
      "* sampling size scheme:\n",
      "   - sample_size_scheme: exponential\n",
      "   - exp_growth_constant: 1.6791331457613021\n",
      "\n",
      "* custom statistics collection:\n",
      "   - no custom statistics callback specified\n",
      "\n",
      "Boundary point after 2 iterations\n",
      "Iter 0: loss=0.42540582570168683496 ||g||=6.738e-01 time=2.243700e-02 dt=2.244e-02 tr_radius=1.000e+00\n",
      "        ||s||=1.000e+00 ||s||_M=1.000e+00 samples Hessian= 814 samples gradient= 32561 samples loss= 32561\n",
      "        epoch=1.025e+00 rho=1.081143e+00 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Boundary point after 5 iterations\n",
      "Iter 1: loss=0.35059131126014375646 ||g||=1.387e-01 time=4.870100e-02 dt=2.626e-02 tr_radius=2.000e+00\n",
      "        ||s||=2.000e+00 ||s||_M=2.000e+00 samples Hessian= 814 samples gradient= 32561 samples loss= 32561\n",
      "        epoch=2.050e+00 rho=1.049023e+00 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Interior point after 4 iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2: loss=0.33652834316422286509 ||g||=5.544e-02 time=7.340300e-02 dt=2.470e-02 tr_radius=4.000e+00\n",
      "        ||s||=9.066e-01 ||s||_M=9.066e-01 samples Hessian= 815 samples gradient= 32561 samples loss= 32561\n",
      "        epoch=3.075e+00 rho=1.148111e+00 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Interior point after 7 iterations\n",
      "Iter 3: loss=0.33359174787331413725 ||g||=1.652e-02 time=9.945800e-02 dt=2.605e-02 tr_radius=4.000e+00\n",
      "        ||s||=9.483e-01 ||s||_M=9.483e-01 samples Hessian= 817 samples gradient= 32561 samples loss= 32561\n",
      "        epoch=4.100e+00 rho=9.456002e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Interior point after 13 iterations\n",
      "Iter 4: loss=0.33335431363592549214 ||g||=3.014e-03 time=1.325240e-01 dt=3.307e-02 tr_radius=4.000e+00\n",
      "        ||s||=3.917e-01 ||s||_M=3.917e-01 samples Hessian= 820 samples gradient= 32561 samples loss= 32561\n",
      "        epoch=5.125e+00 rho=9.678441e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Interior point after 14 iterations\n",
      "Iter 5: loss=0.33334304825720606491 ||g||=8.912e-04 time=1.669160e-01 dt=3.439e-02 tr_radius=4.000e+00\n",
      "        ||s||=8.824e-02 ||s||_M=8.824e-02 samples Hessian= 826 samples gradient= 32561 samples loss= 32561\n",
      "        epoch=6.151e+00 rho=7.360767e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Interior point after 15 iterations\n",
      "Iter 6: loss=0.33334099949485634928 ||g||=3.289e-04 time=1.952980e-01 dt=2.838e-02 tr_radius=4.000e+00\n",
      "        ||s||=3.367e-02 ||s||_M=3.367e-02 samples Hessian= 835 samples gradient= 32561 samples loss= 32561\n",
      "        epoch=7.176e+00 rho=7.931879e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Interior point after 14 iterations\n",
      "Iter 7: loss=0.33334077500235503866 ||g||=1.872e-04 time=2.233610e-01 dt=2.806e-02 tr_radius=4.000e+00\n",
      "        ||s||=1.067e-02 ||s||_M=1.067e-02 samples Hessian= 850 samples gradient= 32561 samples loss= 32561\n",
      "        epoch=8.202e+00 rho=8.649561e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Interior point after 21 iterations\n",
      "Iter 8: loss=0.33334075482073444174 ||g||=2.052e-05 time=2.543810e-01 dt=3.102e-02 tr_radius=4.000e+00\n",
      "        ||s||=4.046e-03 ||s||_M=4.046e-03 samples Hessian= 876 samples gradient= 32561 samples loss= 32561\n",
      "        epoch=9.229e+00 rho=7.723645e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Interior point after 22 iterations\n",
      "Iter 9: loss=0.33334075228986109751 ||g||=7.380e-06 time=2.913110e-01 dt=3.693e-02 tr_radius=4.000e+00\n",
      "        ||s||=1.367e-03 ||s||_M=1.367e-03 samples Hessian= 919 samples gradient= 32561 samples loss= 32561\n",
      "        epoch=1.026e+01 rho=8.401522e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Interior point after 24 iterations\n",
      "Iter 10: loss=0.33334075209566499387 ||g||=2.123e-06 time=3.290040e-01 dt=3.769e-02 tr_radius=4.000e+00\n",
      "         ||s||=4.180e-04 ||s||_M=4.180e-04 samples Hessian= 991 samples gradient= 32561 samples loss= 32561\n",
      "         epoch=1.129e+01 rho=8.019640e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Interior point after 23 iterations\n",
      "Iter 11: loss=0.33334075207087077164 ||g||=8.445e-07 time=3.659800e-01 dt=3.698e-02 tr_radius=4.000e+00\n",
      "         ||s||=1.188e-04 ||s||_M=1.188e-04 samples Hessian= 1112 samples gradient= 32561 samples loss= 32561\n",
      "         epoch=1.232e+01 rho=8.862880e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Interior point after 27 iterations\n",
      "Iter 12: loss=0.33334075206885938059 ||g||=2.649e-07 time=4.014410e-01 dt=3.546e-02 tr_radius=4.000e+00\n",
      "         ||s||=3.377e-05 ||s||_M=3.377e-05 samples Hessian= 1315 samples gradient= 32561 samples loss= 32561\n",
      "         epoch=1.336e+01 rho=9.181598e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Interior point after 28 iterations\n",
      "Iter 13: loss=0.33334075206872315622 ||g||=7.639e-08 time=4.387680e-01 dt=3.733e-02 tr_radius=4.000e+00\n",
      "         ||s||=8.916e-06 ||s||_M=8.916e-06 samples Hessian= 1656 samples gradient= 32561 samples loss= 32561\n",
      "         epoch=1.441e+01 rho=9.552666e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Interior point after 27 iterations\n",
      "Iter 14: loss=0.33334075206871638386 ||g||=2.889e-08 time=4.780100e-01 dt=3.924e-02 tr_radius=4.000e+00\n",
      "         ||s||=2.016e-06 ||s||_M=2.016e-06 samples Hessian= 2229 samples gradient= 32561 samples loss= 32561\n",
      "         epoch=1.548e+01 rho=9.180909e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Interior point after 31 iterations\n",
      "Iter 15: loss=0.33334075206871610630 ||g||=3.967e-09 time=5.351740e-01 dt=5.716e-02 tr_radius=4.000e+00\n",
      "         ||s||=4.332e-07 ||s||_M=4.332e-07 samples Hessian= 3191 samples gradient= 32561 samples loss= 32561\n",
      "         epoch=1.658e+01 rho=9.270392e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Terminating due to gradient tolerance ( grad_norm = 3.757727435781419e-10 < 1e-09 )\n",
      "         195634 function calls in 1.414 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        5    0.000    0.000    1.413    0.283 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2880(run_code)\n",
      "        5    0.000    0.000    1.413    0.283 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.824    0.824 <ipython-input-5-082fc9f9e5e7>:81(<module>)\n",
      "        1    0.003    0.003    0.824    0.824 /media/gronerl/Elements/cleaned_code/scr.py:25(SCR)\n",
      "        1    0.001    0.001    0.588    0.588 <ipython-input-5-082fc9f9e5e7>:100(<module>)\n",
      "        1    0.003    0.003    0.588    0.588 /media/gronerl/Elements/cleaned_code/tr.py:24(Trust_Region)\n",
      "     1698    0.440    0.000    0.440    0.000 {method 'dot' of 'numpy.ndarray' objects}\n",
      "       16    0.016    0.001    0.421    0.026 /media/gronerl/Elements/cleaned_code/scr.py:643(__call__)\n",
      "       34    0.000    0.000    0.366    0.011 <ipython-input-3-e3e29125d14c>:9(loss)\n",
      "       34    0.003    0.000    0.366    0.011 /media/gronerl/Elements/cleaned_code/loss_functions.py:40(logistic_loss)\n",
      "       34    0.000    0.000    0.335    0.010 <ipython-input-3-e3e29125d14c>:12(gradient)\n",
      "       34    0.004    0.000    0.334    0.010 /media/gronerl/Elements/cleaned_code/loss_functions.py:91(logistic_loss_gradient)\n",
      "      239    0.049    0.000    0.266    0.001 /media/gronerl/Elements/cleaned_code/scr.py:763(exact_ARC_suproblem_solver_tridiagonal)\n",
      "      532    0.003    0.000    0.184    0.000 <ipython-input-3-e3e29125d14c>:15(Hv)\n",
      "      532    0.023    0.000    0.176    0.000 /media/gronerl/Elements/cleaned_code/loss_functions.py:208(logistic_loss_Hv)\n",
      "       16    0.031    0.002    0.166    0.010 /media/gronerl/Elements/cleaned_code/tr.py:622(__call__)\n",
      "      566    0.157    0.000    0.161    0.000 /media/gronerl/Elements/cleaned_code/loss_functions.py:500(phi)\n",
      "       34    0.127    0.004    0.128    0.004 /media/gronerl/Elements/cleaned_code/loss_functions.py:509(log_phi)\n",
      "       34    0.112    0.003    0.112    0.003 /media/gronerl/Elements/cleaned_code/loss_functions.py:517(one_minus_log_phi)\n",
      "     1738    0.002    0.000    0.071    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/scipy/linalg/lapack.py:496(get_lapack_funcs)\n",
      "      645    0.010    0.000    0.070    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/scipy/linalg/basic.py:472(solveh_banded)\n",
      "     1738    0.014    0.000    0.069    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/scipy/linalg/blas.py:279(_get_funcs)\n",
      "       36    0.001    0.000    0.063    0.002 /media/gronerl/Elements/cleaned_code/util.py:23(independentSampling)\n",
      "      402    0.011    0.000    0.054    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/scipy/linalg/basic.py:359(solve_banded)\n",
      "     2094    0.012    0.000    0.049    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/scipy/_lib/_util.py:192(_asarray_validated)\n",
      "     1738    0.009    0.000    0.048    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/scipy/linalg/blas.py:218(find_best_blas_type)\n",
      "     2785    0.013    0.000    0.038    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/lib/function_base.py:1170(asarray_chkfinite)\n",
      "      691    0.009    0.000    0.038    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/scipy/linalg/decomp_cholesky.py:194(cholesky_banded)\n",
      "      201    0.003    0.000    0.038    0.000 {built-in method builtins.print}\n",
      "     1738    0.005    0.000    0.036    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/core/numerictypes.py:962(find_common_type)\n",
      "       36    0.034    0.001    0.036    0.001 {method 'choice' of 'mtrand.RandomState' objects}\n",
      "     1730    0.007    0.000    0.034    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/ipykernel/iostream.py:366(write)\n",
      "     1912    0.017    0.000    0.031    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/linalg/linalg.py:2103(norm)\n",
      "     3476    0.022    0.000    0.030    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/core/numerictypes.py:939(_can_coerce_all)\n",
      "     4018    0.028    0.000    0.028    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "       72    0.026    0.000    0.026    0.000 {built-in method torch._C.index_select}\n",
      "     1737    0.005    0.000    0.024    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/ipykernel/iostream.py:195(schedule)\n",
      "     2785    0.003    0.000    0.022    0.000 {method 'all' of 'numpy.ndarray' objects}\n",
      "     2785    0.002    0.000    0.019    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/core/_methods.py:40(_all)\n",
      "     1000    0.003    0.000    0.017    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/lib/function_base.py:5114(append)\n",
      "     1737    0.012    0.000    0.012    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/zmq/sugar/socket.py:333(send)\n",
      "     2186    0.001    0.000    0.012    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/torch/tensor.py:320(__mul__)\n",
      "     2186    0.011    0.000    0.011    0.000 {method 'mul' of 'torch._C.DoubleTensorBase' objects}\n",
      "       16    0.002    0.000    0.010    0.001 /media/gronerl/Elements/cleaned_code/scr.py:970(exact_ARC_subproblem_solver)\n",
      "     2562    0.010    0.000    0.010    0.000 {built-in method numpy.core.multiarray.dot}\n",
      "      667    0.002    0.000    0.010    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/core/fromnumeric.py:1934(any)\n",
      "     7615    0.009    0.000    0.009    0.000 {built-in method numpy.core.multiarray.array}\n",
      "      526    0.000    0.000    0.008    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/torch/tensor.py:311(__sub__)\n",
      "     1000    0.002    0.000    0.008    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/core/fromnumeric.py:1427(ravel)\n",
      "      526    0.008    0.000    0.008    0.000 {method 'sub' of 'torch._C.DoubleTensorBase' objects}\n",
      "      667    0.001    0.000    0.007    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
      "     1156    0.001    0.000    0.007    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/torch/tensor.py:304(__add__)\n",
      "     1405    0.007    0.000    0.007    0.000 {built-in method torch._C.dot}\n",
      "     2683    0.001    0.000    0.006    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/core/numeric.py:495(asanyarray)\n",
      "     1156    0.006    0.000    0.006    0.000 {method 'add' of 'torch._C.DoubleTensorBase' objects}\n",
      "     4852    0.002    0.000    0.006    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/core/numeric.py:424(asarray)\n",
      "     1367    0.001    0.000    0.006    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/torch/tensor.py:341(__div__)\n",
      "      667    0.000    0.000    0.006    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/core/_methods.py:37(_any)\n",
      "     1737    0.003    0.000    0.006    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/threading.py:1104(is_alive)\n",
      "     1600    0.006    0.000    0.006    0.000 {built-in method numpy.core.multiarray.empty}\n",
      "      804    0.002    0.000    0.005    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/core/numerictypes.py:699(issubdtype)\n",
      "     1367    0.005    0.000    0.005    0.000 {method 'div' of 'torch._C.DoubleTensorBase' objects}\n",
      "    14658    0.005    0.000    0.005    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/core/numerictypes.py:948(<listcomp>)\n",
      "     2912    0.005    0.000    0.005    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "     4013    0.005    0.000    0.005    0.000 {built-in method builtins.getattr}\n",
      "     1510    0.005    0.000    0.005    0.000 {built-in method numpy.core.multiarray.zeros}\n",
      "      498    0.001    0.000    0.005    0.000 {method 'max' of 'numpy.ndarray' objects}\n",
      "      845    0.005    0.000    0.005    0.000 {built-in method torch._C.from_numpy}\n",
      "     1000    0.004    0.000    0.004    0.000 {built-in method numpy.core.multiarray.concatenate}\n",
      "       18    0.000    0.000    0.004    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/torch/functional.py:124(matmul)\n",
      "     9589    0.004    0.000    0.004    0.000 {built-in method builtins.isinstance}\n",
      "      498    0.000    0.000    0.004    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/core/_methods.py:25(_amax)\n",
      "        2    0.001    0.000    0.004    0.002 /media/gronerl/Elements/cleaned_code/tr.py:737(exact_TR_subproblem_solver_tridiagonal)\n",
      "      293    0.000    0.000    0.004    0.000 /media/gronerl/Elements/cleaned_code/tr.py:482(MV)\n",
      "     1608    0.002    0.000    0.004    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/core/numerictypes.py:631(issubclass_)\n",
      "     1467    0.004    0.000    0.004    0.000 {built-in method builtins.min}\n",
      "      921    0.003    0.000    0.004    0.000 /media/gronerl/Elements/cleaned_code/scr.py:1108(mitternachtsformel)\n",
      "      114    0.003    0.000    0.003    0.000 {built-in method torch._C.norm}\n",
      "      257    0.001    0.000    0.003    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/core/numeric.py:83(zeros_like)\n",
      "     6458    0.003    0.000    0.003    0.000 {built-in method builtins.issubclass}\n",
      "       18    0.003    0.000    0.003    0.000 {built-in method torch._C.mm}\n",
      "     1737    0.001    0.000    0.003    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/threading.py:1062(_wait_for_tstate_lock)\n",
      "    18880    0.003    0.000    0.003    0.000 {built-in method builtins.len}\n",
      "     2094    0.001    0.000    0.002    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/scipy/sparse/base.py:1202(isspmatrix)\n",
      "      255    0.002    0.000    0.002    0.000 /media/gronerl/Elements/cleaned_code/scr.py:928(growQ)\n",
      "     2615    0.002    0.000    0.002    0.000 {method 'numpy' of 'torch._C.DoubleTensorBase' objects}\n",
      "      277    0.002    0.000    0.002    0.000 /media/gronerl/Elements/cleaned_code/tr.py:928(growQ)\n",
      "      261    0.000    0.000    0.002    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/torch/tensor.py:410(__array__)\n",
      "     1730    0.002    0.000    0.002    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/ipykernel/iostream.py:300(_is_master_process)\n",
      "       81    0.000    0.000    0.002    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/core/fromnumeric.py:1007(argmin)\n",
      "      291    0.002    0.000    0.002    0.000 {built-in method numpy.core.multiarray.copyto}\n",
      "      255    0.001    0.000    0.002    0.000 /media/gronerl/Elements/cleaned_code/scr.py:633(<lambda>)\n",
      "       81    0.000    0.000    0.002    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/core/fromnumeric.py:50(_wrapfunc)\n",
      "       42    0.001    0.000    0.002    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/linalg/linalg.py:534(cholesky)\n",
      "     2060    0.001    0.000    0.002    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/linalg/linalg.py:110(isComplexType)\n",
      "      239    0.002    0.000    0.002    0.000 /media/gronerl/Elements/cleaned_code/scr.py:779(<listcomp>)\n",
      "      271    0.000    0.000    0.002    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/torch/tensor.py:359(__eq__)\n",
      "      514    0.001    0.000    0.002    0.000 <frozen importlib._bootstrap>:997(_handle_fromlist)\n",
      "       36    0.000    0.000    0.002    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2456(prod)\n",
      "      271    0.000    0.000    0.002    0.000 /media/gronerl/Elements/cleaned_code/scr.py:494(MinvV)\n",
      "     2094    0.001    0.000    0.002    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/ma/core.py:6198(isMaskedArray)\n",
      "      239    0.001    0.000    0.001    0.000 /media/gronerl/Elements/cleaned_code/scr.py:781(<listcomp>)\n",
      "     1737    0.001    0.000    0.001    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "      288    0.001    0.000    0.001    0.000 {method 'format' of 'str' objects}\n",
      "       34    0.000    0.000    0.001    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/core/numeric.py:146(ones)\n",
      "     1341    0.001    0.000    0.001    0.000 {built-in method builtins.max}\n",
      "       16    0.000    0.000    0.001    0.000 /media/gronerl/Elements/cleaned_code/scr.py:492(MV)\n",
      "     3603    0.001    0.000    0.001    0.000 {method 'get' of 'dict' objects}\n",
      "     1738    0.001    0.000    0.001    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/core/numerictypes.py:1013(<listcomp>)\n",
      "      271    0.001    0.000    0.001    0.000 {method 'eq' of 'torch._C.DoubleTensorBase' objects}\n",
      "      261    0.001    0.000    0.001    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/torch/tensor.py:418(__array_wrap__)\n",
      "      277    0.000    0.000    0.001    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/torch/tensor.py:356(__neg__)\n",
      "       18    0.001    0.000    0.001    0.000 {method 'unsqueeze' of 'torch._C.DoubleTensorBase' objects}\n",
      "      293    0.000    0.000    0.001    0.000 /media/gronerl/Elements/cleaned_code/tr.py:484(MinvV)\n",
      "      283    0.001    0.000    0.001    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/torch/tensor.py:43(cpu)\n",
      "     1738    0.001    0.000    0.001    0.000 {method 'index' of 'list' objects}\n",
      "        5    0.000    0.000    0.001    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/codeop.py:132(__call__)\n",
      "     1738    0.001    0.000    0.001    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/scipy/linalg/blas.py:259(<listcomp>)\n",
      "        5    0.001    0.000    0.001    0.000 {built-in method builtins.compile}\n",
      "     4577    0.001    0.000    0.001    0.000 {method 'append' of 'list' objects}\n",
      "       81    0.000    0.000    0.001    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/core/fromnumeric.py:37(_wrapit)\n",
      "       64    0.000    0.000    0.001    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/termcolor.py:86(colored)\n",
      "      277    0.001    0.000    0.001    0.000 {method 'neg' of 'torch._C.DoubleTensorBase' objects}\n",
      "       36    0.000    0.000    0.001    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/core/_methods.py:34(_prod)\n",
      "     1737    0.001    0.000    0.001    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/ipykernel/iostream.py:93(_event_pipe)\n",
      "       32    0.001    0.000    0.001    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/linalg/linalg.py:464(inv)\n",
      "      257    0.001    0.000    0.001    0.000 {built-in method numpy.core.multiarray.empty_like}\n",
      "       64    0.000    0.000    0.001    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/os.py:760(getenv)\n",
      "      275    0.000    0.000    0.001    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/torch/tensor.py:308(__iadd__)\n",
      "     1441    0.001    0.000    0.001    0.000 {built-in method math.sqrt}\n",
      "      319    0.000    0.000    0.001    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/torch/_utils.py:6(_type)\n",
      "       64    0.000    0.000    0.001    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/_collections_abc.py:657(get)\n",
      "       16    0.000    0.000    0.001    0.000 /media/gronerl/Elements/cleaned_code/scr.py:975(<listcomp>)\n",
      "     1730    0.001    0.000    0.001    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/ipykernel/iostream.py:313(_schedule_flush)\n",
      "      275    0.001    0.000    0.001    0.000 {method 'add_' of 'torch._C.DoubleTensorBase' objects}\n",
      "      678    0.001    0.000    0.001    0.000 {method 'size' of 'torch._C.DoubleTensorBase' objects}\n",
      "       32    0.000    0.000    0.001    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/core/fromnumeric.py:1778(sum)\n",
      "       64    0.000    0.000    0.001    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/os.py:664(__getitem__)\n",
      "       42    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/lib/twodim_base.py:140(eye)\n",
      "      271    0.000    0.000    0.000    0.000 {method 'all' of 'torch._C.ByteTensorBase' objects}\n",
      "     1692    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/scipy/linalg/misc.py:169(_datacopied)\n",
      "     1028    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "      645    0.000    0.000    0.000    0.000 {method 'conj' of 'numpy.ndarray' objects}\n",
      "     1730    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "     1737    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/threading.py:506(is_set)\n",
      "       32    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/core/_methods.py:31(_sum)\n",
      "       74    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/linalg/linalg.py:138(_commonType)\n",
      "       66    0.000    0.000    0.000    0.000 {built-in method now}\n",
      "       16    0.000    0.000    0.000    0.000 /media/gronerl/Elements/cleaned_code/scr.py:976(<listcomp>)\n",
      "     1119    0.000    0.000    0.000    0.000 {built-in method builtins.abs}\n",
      "     1737    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "     1738    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/core/numerictypes.py:1014(<listcomp>)\n",
      "       81    0.000    0.000    0.000    0.000 {method 'argmin' of 'numpy.ndarray' objects}\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method torch._C.zeros_like}\n",
      "       64    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/os.py:742(encode)\n",
      "       74    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/linalg/linalg.py:208(_assertNdSquareness)\n",
      "       74    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/linalg/linalg.py:105(_makearray)\n",
      "       74    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
      "       14    0.000    0.000    0.000    0.000 /media/gronerl/Elements/cleaned_code/tr.py:731(<listcomp>)\n",
      "       18    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/torch/_utils.py:83(_import_dotted_name)\n",
      "       72    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/core/_internal.py:247(__init__)\n",
      "       16    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/core/fromnumeric.py:1251(diagonal)\n",
      "       16    0.000    0.000    0.000    0.000 {method 'uniform' of 'mtrand.RandomState' objects}\n",
      "       18    0.000    0.000    0.000    0.000 {method 'squeeze_' of 'torch._C.DoubleTensorBase' objects}\n",
      "       24    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/torch/tensor.py:16(new)\n",
      "       74    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/linalg/linalg.py:100(get_linalg_error_extobj)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.__build_class__}\n",
      "        4    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/signal.py:45(signal)\n",
      "       74    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/linalg/linalg.py:123(_realType)\n",
      "      116    0.000    0.000    0.000    0.000 {built-in method builtins.sum}\n",
      "       64    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
      "       36    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C.DoubleTensorBase' objects}\n",
      "       74    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/linalg/linalg.py:197(_assertRankAtLeast2)\n",
      "       32    0.000    0.000    0.000    0.000 {method 'total_seconds' of 'datetime.timedelta' objects}\n",
      "       64    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
      "       18    0.000    0.000    0.000    0.000 {built-in method builtins.__import__}\n",
      "        4    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/signal.py:25(_int_to_enum)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch._C.ones_like}\n",
      "       16    0.000    0.000    0.000    0.000 {method 'diagonal' of 'numpy.ndarray' objects}\n",
      "       18    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
      "        4    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/enum.py:265(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-5-082fc9f9e5e7>:96(<listcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/enum.py:515(__new__)\n",
      "       16    0.000    0.000    0.000    0.000 /media/gronerl/Elements/cleaned_code/scr.py:956(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-5-082fc9f9e5e7>:114(<listcomp>)\n",
      "       72    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/numpy/core/_internal.py:272(get_data)\n",
      "       74    0.000    0.000    0.000    0.000 {method '__array_prepare__' of 'numpy.ndarray' objects}\n",
      "        8    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/signal.py:35(_enum_to_int)\n",
      "        3    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/enum.py:544(_missing_)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-5-082fc9f9e5e7>:116(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-5-082fc9f9e5e7>:115(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-5-082fc9f9e5e7>:98(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-5-082fc9f9e5e7>:97(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/torch/tensor.py:110(shape)\n",
      "        5    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/IPython/core/hooks.py:142(__call__)\n",
      "        5    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/IPython/utils/ipstruct.py:125(__getattr__)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method _signal.signal}\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-5-082fc9f9e5e7>:151(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 /media/gronerl/Elements/cleaned_code/scr.py:622(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 /media/gronerl/Elements/cleaned_code/tr.py:617(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 /media/gronerl/Elements/cleaned_code/tr.py:755(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 /media/gronerl/Elements/cleaned_code/tr.py:757(<listcomp>)\n",
      "        5    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/IPython/core/interactiveshell.py:1069(user_global_ns)\n",
      "        5    0.000    0.000    0.000    0.000 /home/gronerl/anaconda3/envs/SCRDemo/lib/python3.6/site-packages/IPython/core/hooks.py:207(pre_run_code_hook)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-5-082fc9f9e5e7>:135(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 /media/gronerl/Elements/cleaned_code/tr.py:332(AbortException)\n",
      "        1    0.000    0.000    0.000    0.000 /media/gronerl/Elements/cleaned_code/scr.py:342(AbortException)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-5-082fc9f9e5e7>:118(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_runs = 1 # repeat experiments to lower effect of randomness\n",
    "\n",
    "# The following parameters are optional in the sense that default values are set if not specified.\n",
    "\n",
    "#options common to all algorithms\n",
    "opt = {}\n",
    "opt['grad_tol'] = 1e-9\n",
    "\n",
    "#common to tr and scr\n",
    "opt_tr = dict(opt)\n",
    "\n",
    "opt_tr['max_iterations'] = 20\n",
    "opt_tr['sample_size_scheme'] = 'exponential'#alternatives constant,linear,exponential,adaptive\n",
    "#scaling matrix/M-norm. alternatives have specific parameters, see source code\n",
    "opt_tr['scaling_matrix'] = 'uniform'#alternatives adagrad,rmsprop,adadelta,approximate_hessian_diagonal,GGT\n",
    "opt_tr['successful_treshold']=0.1\n",
    "opt_tr['very_successful_treshold']=0.9\n",
    "# Sampling\n",
    "opt_tr['Hessian_sampling']=True\n",
    "opt_tr['gradient_sampling']=False\n",
    "opt_tr['unsuccessful_sample_scaling']=1.5\n",
    "opt_tr['sample_scaling_Hessian']=1\n",
    "opt_tr['sample_scaling_gradient']=1\n",
    "opt_tr['krylov_tol']=1e-1\n",
    "opt_tr['exact_tol']=1e-7\n",
    "opt_tr['initial_sample_size_Hessian']=0.025*n\n",
    "opt_tr['initial_sample_size_gradient']=0.25*n\n",
    "\n",
    "opt_scr = dict(opt_tr)\n",
    "\n",
    "#tr only\n",
    "\n",
    "opt_tr['initial_trust_radius']=1.0\n",
    "opt_tr['radius_increase_multiplier']=2.    # multiply by..\n",
    "opt_tr['radius_decrease_multiplier']=2.     # divide by..\n",
    "opt_tr['subproblem_solver']='GLTR' # alternatives: GLTR, cauchy, CG (implements Steihaug-CG), without GPU and scaling support: exact, dog_leg,\n",
    "\n",
    "#scr only\n",
    "opt_scr['initial_penalty']=0.01\n",
    "opt_scr['penalty_increase_multiplier']=2.    # multiply by..\n",
    "opt_scr['penalty_decrease_multiplier']=2.     # divide by..\n",
    "\n",
    "opt_scr['initial_penalty_parameter']=0.01\n",
    "opt_scr['subproblem_solver']='lanczos' # alternatives: lanczos, cauchy, exact\n",
    "opt_scr['solve_each_i-th_krylov_space']=1 #===1 in TR\n",
    "opt_scr['keep_Q_matrix_in_memory']=True #===True in TR\n",
    "\n",
    "### SGD:\n",
    "opt_sgd = dict(opt)\n",
    "opt_sgd['method_name']='SGD'\n",
    "opt_sgd['max_epochs']=9\n",
    "opt_sgd['learning_rate']=1e-1 # This SGD implementation expects a constant step size\n",
    "opt_sgd['batch_size']=0.001*n\n",
    "opt_sgd['replacement']=True #False slows down sampling \n",
    "\n",
    "### SAGA:\n",
    "opt_saga = {}\n",
    "opt_saga['n_epochs_saga']=10\n",
    "opt_saga['learning_rate_saga']=1e-2\n",
    "\n",
    "\n",
    "\n",
    "######################\n",
    "#### Run Methods #####\n",
    "######################\n",
    "\n",
    "SCR= True\n",
    "TR= True\n",
    "SGD= False\n",
    "SAGA= False\n",
    "\n",
    "# If running on GPU and profile==True, make sure that CUDA_LAUNCH_BLOCKING=1\n",
    "# is set in the environment, otherwise the results of the profiler will be bogus.\n",
    "profile = True \n",
    "if profile:\n",
    "    import cProfile, pstats, io\n",
    "    pr = cProfile.Profile()\n",
    "    pr.enable()\n",
    "    \n",
    "    \n",
    "if SCR:\n",
    "    loss_collector=[]\n",
    "    timings_collector=[]\n",
    "    samples_collector=[]\n",
    "    \n",
    "    for k in range(n_runs): \n",
    "        SCR_loss=[]\n",
    "        SCR_x=[]\n",
    "        (w_SCR, _s)=scr.SCR(w,loss_computation,gradient_computation,\n",
    "                                                Hv=hessian_vector_computation,hessian=hessian_computation,\n",
    "                                                X=X, Y=Y, opt=opt_scr, **loss_args)\n",
    "        loss_collector.append(_s['loss'])\n",
    "        timings_collector.append(_s['time'])\n",
    "        samples_collector.append(_s['samples'])\n",
    "\n",
    "    SCR_loss = [float(sum(col))/len(col) for col in zip(*loss_collector)]\n",
    "    SCR_x = [float(sum(col))/len(col) for col in zip(*timings_collector)]    \n",
    "    SCR_samples= [float(sum(col))/len(col) for col in zip(*samples_collector)] \n",
    "    \n",
    "if TR:\n",
    "    loss_collector=[]\n",
    "    timings_collector=[]\n",
    "    samples_collector=[]\n",
    "    for k in range(n_runs): \n",
    "        TR_loss=[]\n",
    "        TR_x=[]\n",
    "        (w_TR,_s)=tr.Trust_Region(w,loss_computation,gradient_computation,\n",
    "                                                      Hv=hessian_vector_computation, hessian=hessian_computation,\n",
    "                                                      X=X, Y=Y, opt=opt_tr,**loss_args)\n",
    "        loss_collector.append(_s['loss'])\n",
    "        timings_collector.append(_s['time'])\n",
    "        samples_collector.append(_s['samples'])\n",
    "        \n",
    "    TR_loss = [float(sum(col))/len(col) for col in zip(*loss_collector)]\n",
    "    TR_x = [float(sum(col))/len(col) for col in zip(*timings_collector)]    \n",
    "    TR_samples= [float(sum(col))/len(col) for col in zip(*samples_collector)] \n",
    "    \n",
    "if SGD:\n",
    "    loss_collector=[]\n",
    "    timings_collector=[]\n",
    "    samples_collector=[]\n",
    "    \n",
    "    for k in range(n_runs): \n",
    "        SGD_loss=[]\n",
    "        SGD_x=[]\n",
    "        (w_SGD,_s)=gradient_methods.Gradient_Method(w,loss_computation,gradient_computation, X=X, Y=Y, opt=opt_sgd, **loss_args)\n",
    "        loss_collector.append(_s['loss'])\n",
    "        timings_collector.append(_s['time'])\n",
    "        samples_collector.append(_s['samples'])\n",
    "\n",
    "    SGD_loss = [float(sum(col))/len(col) for col in zip(*loss_collector)]\n",
    "    SGD_x = [float(sum(col))/len(col) for col in zip(*timings_collector)]    \n",
    "    SGD_samples= [float(sum(col))/len(col) for col in zip(*samples_collector)]\n",
    "    \n",
    "if SAGA:\n",
    "    loss_collector=[]\n",
    "    timings_collector=[]\n",
    "    samples_collector=[]\n",
    "    \n",
    "    for k in range(n_runs): \n",
    "        SAGA_loss=[]\n",
    "        SAGA_x=[]\n",
    "        (w_SAGA,_s)=saga.SAGA(w,loss_computation_numpy,gradient_computation_numpy, X=X, Y=Y, opt=opt_saga, **loss_args)\n",
    "        loss_collector.append(_s['loss'])\n",
    "        timings_collector.append(_s['time'])\n",
    "        samples_collector.append(_s['samples'])\n",
    "\n",
    "    SAGA_loss = [float(sum(col))/len(col) for col in zip(*loss_collector)]\n",
    "    SAGA_x = [float(sum(col))/len(col) for col in zip(*timings_collector)]    \n",
    "    SAGA_samples= [float(sum(col))/len(col) for col in zip(*samples_collector)] \n",
    "if profile:\n",
    "    pr.disable()\n",
    "    s = io.StringIO()\n",
    "    sortby = 'cumulative'\n",
    "    ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
    "    ps.print_stats()\n",
    "    print(s.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "show_plots(x_limits_time=(0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Subsampled Cubic Regularization ---\n",
      "\n",
      "cardinality of dataset n = 60000\n",
      "dimension of parameter space d = 79510\n",
      "\n",
      "\n",
      "SCR configuration:\n",
      "\n",
      "* (outer) termination criteria \n",
      "   - max_iterations: 20\n",
      "   - grad_tol: 1e-09\n",
      "\n",
      "* trust region adaption parameters:\n",
      "   - initial_penalty: 0.01\n",
      "   - min_penalty: 0.0\n",
      "   - successful_threshold: 0.1\n",
      "   - very_successful_threshold: 0.9\n",
      "   - penalty_increase_multiplier: 2.0\n",
      "   - penalty_decrease_multiplier: 2.0\n",
      "   - accept_all_decreasing_steps: True\n",
      "\n",
      "* subsolver and related parameters:\n",
      "   - subproblem_solver: lanczos\n",
      "   - krylov_tol: 0.1\n",
      "   - exact_tol: 1e-07\n",
      "   - lanczos_termination_criterion: g\n",
      "   - solve_each_i_th_krylov_space: 1\n",
      "   - keep_Q_matrix_in_memory: True\n",
      "\n",
      "* trust region shape and related parameters:\n",
      "   - scaling_matrix:  uniform\n",
      "\n",
      "* sampling parameters:\n",
      "   - replacement: False\n",
      "   - sampling_scheme: independent\n",
      "   - Hessian_sampling_flag: True\n",
      "   - initial_sample_size_Hessian: 814\n",
      "   - gradient_sampling_flag: False\n",
      "   - loss_sampling_flag: False\n",
      "\n",
      "* sampling size scheme:\n",
      "   - sample_size_scheme: exponential\n",
      "   - exp_growth_constant: 1.73225151363302\n",
      "\n",
      "* custom statistics collection:\n",
      "   - no custom statistics callback specified\n",
      "\n",
      "Lanczos converged after 6 iterations\n",
      "Iter 0: loss=2.27819347381591796875 ||g||=2.972e-02 time=2.119623e+00 dt=2.120e+00 penalty=5.000e-03\n",
      "        ||s||=1.960e+00 ||s||_M=1.960e+00 samples Hessian= 814 samples Gradient= 60000 samples loss= 60000\n",
      "        epoch=2.027e+00 rho=1.392287e+00 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Lanczos converged after 9 iterations\n",
      "Iter 1: loss=2.27819347381591796875 ||g||=5.292e-02 time=4.055629e+00 dt=1.936e+00 penalty=1.000e-02\n",
      "        ||s||=4.844e+00 ||s||_M=4.844e+00 samples Hessian= 814 samples Gradient= 60000 samples loss= 60000\n",
      "        epoch=4.054e+00 rho=-6.636324e-02 accepted= \u001b[31mFalse\u001b[0m successful=\u001b[31mFalse\u001b[0m \n",
      "\n",
      "Lanczos converged after 7 iterations\n",
      "Iter 2: loss=2.27819347381591796875 ||g||=5.292e-02 time=4.909997e+00 dt=8.544e-01 penalty=2.000e-02\n",
      "        ||s||=2.815e+00 ||s||_M=2.815e+00 samples Hessian= 816 samples Gradient= 60000 samples loss= 60000\n",
      "        epoch=6.081e+00 rho=-6.097069e-02 accepted= \u001b[31mFalse\u001b[0m successful=\u001b[31mFalse\u001b[0m \n",
      "\n",
      "Lanczos converged after 5 iterations\n",
      "Iter 3: loss=2.27819347381591796875 ||g||=5.292e-02 time=5.697248e+00 dt=7.873e-01 penalty=4.000e-02\n",
      "        ||s||=1.728e+00 ||s||_M=1.728e+00 samples Hessian= 818 samples Gradient= 60000 samples loss= 60000\n",
      "        epoch=8.109e+00 rho=-9.138911e-02 accepted= \u001b[31mFalse\u001b[0m successful=\u001b[31mFalse\u001b[0m \n",
      "\n",
      "Lanczos converged after 4 iterations\n",
      "Iter 4: loss=2.27819347381591796875 ||g||=5.292e-02 time=6.470443e+00 dt=7.732e-01 penalty=8.000e-02\n",
      "        ||s||=1.131e+00 ||s||_M=1.131e+00 samples Hessian= 822 samples Gradient= 60000 samples loss= 60000\n",
      "        epoch=1.014e+01 rho=-3.070857e-01 accepted= \u001b[31mFalse\u001b[0m successful=\u001b[31mFalse\u001b[0m \n",
      "\n",
      "Lanczos converged after 4 iterations\n",
      "Iter 5: loss=2.27819347381591796875 ||g||=5.292e-02 time=7.230788e+00 dt=7.603e-01 penalty=1.600e-01\n",
      "        ||s||=7.675e-01 ||s||_M=7.675e-01 samples Hessian= 828 samples Gradient= 60000 samples loss= 60000\n",
      "        epoch=1.216e+01 rho=-4.004265e-01 accepted= \u001b[31mFalse\u001b[0m successful=\u001b[31mFalse\u001b[0m \n",
      "\n",
      "Lanczos converged after 3 iterations\n",
      "Iter 6: loss=2.27819347381591796875 ||g||=5.292e-02 time=7.897769e+00 dt=6.670e-01 penalty=3.200e-01\n",
      "        ||s||=5.312e-01 ||s||_M=5.312e-01 samples Hessian= 840 samples Gradient= 60000 samples loss= 60000\n",
      "        epoch=1.419e+01 rho=-6.631564e-02 accepted= \u001b[31mFalse\u001b[0m successful=\u001b[31mFalse\u001b[0m \n",
      "\n",
      "Lanczos converged after 3 iterations\n",
      "Iter 7: loss=2.27237248420715332031 ||g||=5.292e-02 time=8.603567e+00 dt=7.058e-01 penalty=3.200e-01\n",
      "        ||s||=3.760e-01 ||s||_M=3.760e-01 samples Hessian= 859 samples Gradient= 60000 samples loss= 60000\n",
      "        epoch=1.622e+01 rho=4.732096e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Lanczos converged after 2 iterations\n",
      "Iter 8: loss=2.26103067398071289062 ||g||=8.412e-02 time=1.038395e+01 dt=1.780e+00 penalty=1.600e-01\n",
      "        ||s||=2.950e-01 ||s||_M=2.950e-01 samples Hessian= 894 samples Gradient= 60000 samples loss= 60000\n",
      "        epoch=1.825e+01 rho=1.232344e+00 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Lanczos converged after 3 iterations\n",
      "Iter 9: loss=2.25120568275451660156 ||g||=2.446e-02 time=1.211404e+01 dt=1.730e+00 penalty=8.000e-02\n",
      "        ||s||=3.993e-01 ||s||_M=3.993e-01 samples Hessian= 953 samples Gradient= 60000 samples loss= 60000\n",
      "        epoch=2.028e+01 rho=1.499269e+00 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Lanczos converged after 3 iterations\n",
      "Iter 10: loss=2.23682403564453125000 ||g||=2.502e-02 time=1.386165e+01 dt=1.748e+00 penalty=4.000e-02\n",
      "         ||s||=5.693e-01 ||s||_M=5.693e-01 samples Hessian= 1056 samples Gradient= 60000 samples loss= 60000\n",
      "         epoch=2.232e+01 rho=1.503877e+00 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Lanczos converged after 3 iterations\n",
      "Iter 11: loss=2.21770358085632324219 ||g||=2.526e-02 time=1.555114e+01 dt=1.689e+00 penalty=2.000e-02\n",
      "         ||s||=7.855e-01 ||s||_M=7.855e-01 samples Hessian= 1234 samples Gradient= 60000 samples loss= 60000\n",
      "         epoch=2.436e+01 rho=1.460975e+00 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Lanczos converged after 6 iterations\n",
      "Iter 12: loss=2.19270253181457519531 ||g||=2.393e-02 time=1.742410e+01 dt=1.873e+00 penalty=1.000e-02\n",
      "         ||s||=1.098e+00 ||s||_M=1.098e+00 samples Hessian= 1543 samples Gradient= 60000 samples loss= 60000\n",
      "         epoch=2.641e+01 rho=1.478221e+00 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Lanczos converged after 6 iterations\n",
      "Iter 13: loss=2.16174340248107910156 ||g||=2.258e-02 time=1.937243e+01 dt=1.948e+00 penalty=5.000e-03\n",
      "         ||s||=1.480e+00 ||s||_M=1.480e+00 samples Hessian= 2077 samples Gradient= 60000 samples loss= 60000\n",
      "         epoch=2.848e+01 rho=1.445402e+00 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Lanczos converged after 13 iterations\n",
      "Iter 14: loss=2.05182766914367675781 ||g||=2.118e-02 time=2.197258e+01 dt=2.600e+00 penalty=5.000e-03\n",
      "         ||s||=5.414e+00 ||s||_M=5.414e+00 samples Hessian= 3003 samples Gradient= 60000 samples loss= 60000\n",
      "         epoch=3.058e+01 rho=7.809054e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Lanczos converged after 10 iterations\n",
      "Iter 15: loss=2.05182766914367675781 ||g||=7.187e-02 time=2.476886e+01 dt=2.796e+00 penalty=1.000e-02\n",
      "         ||s||=5.576e+00 ||s||_M=5.576e+00 samples Hessian= 4607 samples Gradient= 60000 samples loss= 60000\n",
      "         epoch=3.273e+01 rho=-7.203295e-01 accepted= \u001b[31mFalse\u001b[0m successful=\u001b[31mFalse\u001b[0m \n",
      "\n",
      "Lanczos converged after 7 iterations\n",
      "Iter 16: loss=2.04993057250976562500 ||g||=7.187e-02 time=2.615009e+01 dt=1.381e+00 penalty=2.000e-02\n",
      "         ||s||=3.080e+00 ||s||_M=3.080e+00 samples Hessian= 7386 samples Gradient= 60000 samples loss= 60000\n",
      "         epoch=3.498e+01 rho=1.586698e-02 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[31mFalse\u001b[0m \n",
      "\n",
      "Lanczos converged after 7 iterations\n",
      "Iter 17: loss=2.01143741607666015625 ||g||=1.912e-01 time=2.983610e+01 dt=3.686e+00 penalty=4.000e-02\n",
      "         ||s||=6.699e+00 ||s||_M=6.699e+00 samples Hessian= 12199 samples Gradient= 60000 samples loss= 60000\n",
      "         epoch=3.739e+01 rho=3.319663e-02 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[31mFalse\u001b[0m \n",
      "\n",
      "Lanczos converged after 4 iterations\n",
      "Iter 18: loss=1.97577333450317382812 ||g||=1.044e-01 time=3.321438e+01 dt=3.378e+00 penalty=2.000e-02\n",
      "         ||s||=8.503e-01 ||s||_M=8.503e-01 samples Hessian= 20537 samples Gradient= 60000 samples loss= 60000\n",
      "         epoch=4.007e+01 rho=1.108324e+00 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Lanczos converged after 6 iterations\n",
      "Iter 19: loss=1.95420038700103759766 ||g||=2.542e-02 time=3.924357e+01 dt=6.029e+00 penalty=1.000e-02\n",
      "         ||s||=1.007e+00 ||s||_M=1.007e+00 samples Hessian= 34980 samples Gradient= 60000 samples loss= 60000\n",
      "         epoch=4.324e+01 rho=1.463788e+00 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Terminating due to iteration limit\n",
      "--- Trust Region ---\n",
      "\n",
      "cardinality of dataset n = 60000\n",
      "dimension of parameter space d = 79510\n",
      "\n",
      "\n",
      "TR configuration:\n",
      "\n",
      "* (outer) termination criteria \n",
      "   - max_iterations: 20\n",
      "   - grad_tol: 1e-09\n",
      "\n",
      "* trust region adaption parameters:\n",
      "   - initial_trust_radius: 1.0\n",
      "   - max_trust_radius: inf\n",
      "   - successful_threshold: 0.1\n",
      "   - very_successful_threshold: 0.9\n",
      "   - radius_decrease_multiplier: 2.0\n",
      "   - radius_increase_multiplier: 2.0\n",
      "   - accept_all_decreasing_steps: True\n",
      "\n",
      "* subsolver and related parameters:\n",
      "   - subproblem_solver: GLTR\n",
      "   - krylov_tol: 0.1\n",
      "   - exact_tol: 1e-07\n",
      "\n",
      "* trust region shape and related parameters:\n",
      "   - scaling_matrix:  uniform\n",
      "\n",
      "* sampling parameters:\n",
      "   - replacement: False\n",
      "   - sampling_scheme: independent\n",
      "   - Hessian_sampling_flag: True\n",
      "   - initial_sample_size_Hessian: 814\n",
      "   - gradient_sampling_flag: False\n",
      "   - loss_sampling_flag: False\n",
      "\n",
      "* sampling size scheme:\n",
      "   - sample_size_scheme: exponential\n",
      "   - exp_growth_constant: 1.73225151363302\n",
      "\n",
      "* custom statistics collection:\n",
      "   - custom statistics callback specified\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 2.302700996398926\n",
      "Boundary point after 3 iterations\n",
      "Iter 0: loss=2.29437518119812011719 ||g||=2.972e-02 time=1.542449e+00 dt=1.542e+00 tr_radius=1.000e+00\n",
      "        ||s||=1.000e+00 ||s||_M=1.000e+00 samples Hessian= 814 samples gradient= 60000 samples loss= 60000\n",
      "        epoch=1.014e+00 rho=7.209232e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Validation loss: 2.2935030460357666\n",
      "Boundary point after 3 iterations\n",
      "Iter 1: loss=2.28563642501831054688 ||g||=2.879e-02 time=3.424787e+00 dt=1.882e+00 tr_radius=1.000e+00\n",
      "        ||s||=1.000e+00 ||s||_M=1.000e+00 samples Hessian= 814 samples gradient= 60000 samples loss= 60000\n",
      "        epoch=2.027e+00 rho=4.061929e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Validation loss: 2.2846169471740723\n",
      "Boundary point after 4 iterations\n",
      "Iter 2: loss=2.27724099159240722656 ||g||=7.744e-02 time=5.240576e+00 dt=1.816e+00 tr_radius=1.000e+00\n",
      "        ||s||=1.000e+00 ||s||_M=1.000e+00 samples Hessian= 816 samples gradient= 60000 samples loss= 60000\n",
      "        epoch=3.041e+00 rho=1.525181e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Validation loss: 2.2752432823181152\n",
      "Boundary point after 4 iterations\n",
      "Iter 3: loss=2.27724099159240722656 ||g||=5.436e-02 time=7.056943e+00 dt=1.816e+00 tr_radius=1.000e+00\n",
      "        ||s||=1.000e+00 ||s||_M=1.000e+00 samples Hessian= 818 samples gradient= 60000 samples loss= 60000\n",
      "        epoch=4.054e+00 rho=-1.713660e-01 accepted= \u001b[31mFalse\u001b[0m successful=\u001b[31mFalse\u001b[0m \n",
      "\n",
      "Validation loss: 2.2752432823181152\n",
      "Boundary point after 2 iterations\n",
      "Iter 4: loss=2.26569819450378417969 ||g||=5.436e-02 time=7.695726e+00 dt=6.388e-01 tr_radius=5.000e-01\n",
      "        ||s||=5.000e-01 ||s||_M=5.000e-01 samples Hessian= 822 samples gradient= 60000 samples loss= 60000\n",
      "        epoch=5.068e+00 rho=3.006824e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Validation loss: 2.264143943786621\n",
      "Boundary point after 4 iterations\n",
      "Iter 5: loss=2.24661517143249511719 ||g||=1.140e-01 time=9.661334e+00 dt=1.966e+00 tr_radius=5.000e-01\n",
      "        ||s||=5.000e-01 ||s||_M=5.000e-01 samples Hessian= 828 samples gradient= 60000 samples loss= 60000\n",
      "        epoch=6.082e+00 rho=8.601348e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Validation loss: 2.244096517562866\n",
      "Boundary point after 4 iterations\n",
      "Iter 6: loss=2.23390126228332519531 ||g||=3.164e-02 time=1.147087e+01 dt=1.810e+00 tr_radius=5.000e-01\n",
      "        ||s||=5.000e-01 ||s||_M=5.000e-01 samples Hessian= 840 samples gradient= 60000 samples loss= 60000\n",
      "        epoch=7.096e+00 rho=9.926230e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Validation loss: 2.2311668395996094\n",
      "Boundary point after 7 iterations\n",
      "Iter 7: loss=2.20999002456665039062 ||g||=2.470e-02 time=1.339355e+01 dt=1.923e+00 tr_radius=1.000e+00\n",
      "        ||s||=1.000e+00 ||s||_M=1.000e+00 samples Hessian= 859 samples gradient= 60000 samples loss= 60000\n",
      "        epoch=8.110e+00 rho=9.760504e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Validation loss: 2.2068939208984375\n",
      "Boundary point after 7 iterations\n",
      "Iter 8: loss=2.17164564132690429688 ||g||=2.390e-02 time=1.521915e+01 dt=1.826e+00 tr_radius=2.000e+00\n",
      "        ||s||=2.000e+00 ||s||_M=2.000e+00 samples Hessian= 894 samples gradient= 60000 samples loss= 60000\n",
      "        epoch=9.125e+00 rho=7.707231e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Validation loss: 2.1682567596435547\n",
      "Boundary point after 11 iterations\n",
      "Iter 9: loss=2.09606409072875976562 ||g||=3.326e-02 time=1.732966e+01 dt=2.111e+00 tr_radius=2.000e+00\n",
      "        ||s||=2.000e+00 ||s||_M=2.000e+00 samples Hessian= 953 samples gradient= 60000 samples loss= 60000\n",
      "        epoch=1.014e+01 rho=1.080483e+00 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Validation loss: 2.090496301651001\n",
      "Boundary point after 9 iterations\n",
      "Iter 10: loss=2.09606409072875976562 ||g||=8.726e-02 time=1.934971e+01 dt=2.020e+00 tr_radius=4.000e+00\n",
      "         ||s||=4.000e+00 ||s||_M=4.000e+00 samples Hessian= 1056 samples gradient= 60000 samples loss= 60000\n",
      "         epoch=1.116e+01 rho=-2.376008e-01 accepted= \u001b[31mFalse\u001b[0m successful=\u001b[31mFalse\u001b[0m \n",
      "\n",
      "Validation loss: 2.090496301651001\n",
      "Boundary point after 8 iterations\n",
      "Iter 11: loss=2.06926751136779785156 ||g||=8.726e-02 time=2.019297e+01 dt=8.433e-01 tr_radius=2.000e+00\n",
      "         ||s||=2.000e+00 ||s||_M=2.000e+00 samples Hessian= 1234 samples gradient= 60000 samples loss= 60000\n",
      "         epoch=1.218e+01 rho=1.369762e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Validation loss: 2.0619568824768066\n",
      "Boundary point after 5 iterations\n",
      "Iter 12: loss=2.05947589874267578125 ||g||=3.322e-01 time=2.214905e+01 dt=1.956e+00 tr_radius=2.000e+00\n",
      "         ||s||=2.000e+00 ||s||_M=2.000e+00 samples Hessian= 1543 samples gradient= 60000 samples loss= 60000\n",
      "         epoch=1.320e+01 rho=1.201410e-02 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[31mFalse\u001b[0m \n",
      "\n",
      "Validation loss: 2.05279278755188\n",
      "Boundary point after 4 iterations\n",
      "Iter 13: loss=2.04892897605895996094 ||g||=1.381e-01 time=2.428589e+01 dt=2.137e+00 tr_radius=1.000e+00\n",
      "         ||s||=1.000e+00 ||s||_M=1.000e+00 samples Hessian= 2077 samples gradient= 60000 samples loss= 60000\n",
      "         epoch=1.424e+01 rho=1.044127e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Validation loss: 2.041473627090454\n",
      "Boundary point after 5 iterations\n",
      "Iter 14: loss=2.02810049057006835938 ||g||=6.387e-02 time=2.651913e+01 dt=2.233e+00 tr_radius=1.000e+00\n",
      "         ||s||=1.000e+00 ||s||_M=1.000e+00 samples Hessian= 3003 samples gradient= 60000 samples loss= 60000\n",
      "         epoch=1.529e+01 rho=1.523306e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Validation loss: 2.021359443664551\n",
      "Boundary point after 7 iterations\n",
      "Iter 15: loss=2.02810049057006835938 ||g||=9.289e-02 time=2.907289e+01 dt=2.554e+00 tr_radius=1.000e+00\n",
      "         ||s||=1.000e+00 ||s||_M=1.000e+00 samples Hessian= 4607 samples gradient= 60000 samples loss= 60000\n",
      "         epoch=1.637e+01 rho=-2.264739e-02 accepted= \u001b[31mFalse\u001b[0m successful=\u001b[31mFalse\u001b[0m \n",
      "\n",
      "Validation loss: 2.021359443664551\n",
      "Boundary point after 4 iterations\n",
      "Iter 16: loss=2.00623726844787597656 ||g||=9.289e-02 time=3.009327e+01 dt=1.020e+00 tr_radius=5.000e-01\n",
      "         ||s||=5.000e-01 ||s||_M=5.000e-01 samples Hessian= 7386 samples gradient= 60000 samples loss= 60000\n",
      "         epoch=1.749e+01 rho=5.711202e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Validation loss: 1.9992437362670898\n",
      "Boundary point after 5 iterations\n",
      "Iter 17: loss=1.98785388469696044922 ||g||=4.426e-02 time=3.332367e+01 dt=3.230e+00 tr_radius=5.000e-01\n",
      "         ||s||=5.000e-01 ||s||_M=5.000e-01 samples Hessian= 12199 samples gradient= 60000 samples loss= 60000\n",
      "         epoch=1.869e+01 rho=1.009457e+00 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Validation loss: 1.980855107307434\n",
      "Boundary point after 6 iterations\n",
      "Iter 18: loss=1.94812130928039550781 ||g||=3.649e-02 time=3.794346e+01 dt=4.620e+00 tr_radius=1.000e+00\n",
      "         ||s||=1.000e+00 ||s||_M=1.000e+00 samples Hessian= 20537 samples gradient= 60000 samples loss= 60000\n",
      "         epoch=2.004e+01 rho=8.450128e-01 accepted= \u001b[32mTrue\u001b[0m successful=\u001b[32mTrue\u001b[0m \n",
      "\n",
      "Validation loss: 1.9415451288223267\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "n_runs = 1 \n",
    "\n",
    "n_runs = 1 # repeat experiments to lower effect of randomness\n",
    "\n",
    "# The following parameters are optional in the sense that default values are set if not specified.\n",
    "\n",
    "#options common to all algorithms\n",
    "opt = {}\n",
    "opt['grad_tol'] = 1e-9\n",
    "\n",
    "#common to tr and scr\n",
    "opt_tr = dict(opt)\n",
    "opt_tr['penalty_increase_multiplier']=2.    # multiply by..\n",
    "opt_tr['penalty_decrease_multiplier']=2.     # divide by..\n",
    "\n",
    "### TR and SCR:\n",
    "opt_tr['max_iterations'] = 20\n",
    "opt_tr['sample_size_scheme'] = 'exponential'#alternatives constant,linear,exponential,adaptive\n",
    "#scaling matrix/M-norm. alternatives have specific parameters, see source code\n",
    "opt_tr['scaling_matrix'] = 'uniform'#alternatives adagrad,rmsprop,adadelta,approximate_hessian_diagonal,GGT\n",
    "opt_tr['successful_treshold']=0.1\n",
    "opt_tr['very_successful_treshold']=0.9\n",
    "# Sampling\n",
    "opt_tr['Hessian_sampling']=True\n",
    "opt_tr['gradient_sampling']=False\n",
    "opt_tr['unsuccessful_sample_scaling']=1.5\n",
    "opt_tr['sample_scaling_Hessian']=1\n",
    "opt_tr['sample_scaling_gradient']=1\n",
    "opt_tr['krylov_tol']=1e-1\n",
    "opt_tr['exact_tol']=1e-7\n",
    "\n",
    "opt_scr = dict(opt_tr)\n",
    "\n",
    "#tr only\n",
    "opt_tr['initial_sample_size_Hessian']=0.025*n\n",
    "opt_tr['initial_sample_size_gradient']=0.25*n\n",
    "opt_tr['initial_trust_radius']=1.0\n",
    "opt_tr['subproblem_solver']='GLTR' # alternatives: GLTR, cauchy, CG (implements Steihaug-CG), without GPU and scaling support: exact, dog_leg,\n",
    "\n",
    "#scr only\n",
    "opt_scr['initial_sample_size_Hessian']=0.025*n\n",
    "opt_scr['initial_sample_size_gradient']=0.25*n\n",
    "opt_scr['initial_penalty']=0.01\n",
    "opt_scr['subproblem_solver']='lanczos' # alternatives: lanczos, cauchy, exact\n",
    "opt_scr['solve_each_i-th_krylov_space']=1 #===1 in TR\n",
    "opt_scr['keep_Q_matrix_in_memory']=True #===True in TR\n",
    "\n",
    "### SGD:\n",
    "opt_sgd = dict(opt)\n",
    "opt_sgd['method_name']='SGD'\n",
    "opt_sgd['max_epochs']=9\n",
    "opt_sgd['learning_rate']=1e-1 # This SGD implementation expects a constant step size\n",
    "opt_sgd['batch_size']=0.001*n\n",
    "opt_sgd['replacement']=True #False slows down sampling \n",
    "\n",
    "### SAGA:\n",
    "opt_saga = {}\n",
    "opt_saga['n_epochs_saga']=10\n",
    "opt_saga['learning_rate_saga']=1e-2\n",
    "\n",
    "dataset_name = 'mnist-c' # try: 'a9a','mnist-c','mnist-a','cifar-c'\n",
    "\n",
    "if dataset_name=='a9a':\n",
    "    X, Y = load_svmlight_file('data/a9a')\n",
    "    X = X.toarray()\n",
    "    Y= [0 if e == -1 else e for e in Y]\n",
    "    Y=np.array(Y)      \n",
    "    d = X.shape[1]\n",
    "    n = X.shape[0]\n",
    "    X = torch.from_numpy(X)\n",
    "    Y = torch.from_numpy(Y).long()\n",
    "    X_valid = X[:25000]\n",
    "    Y_valid = Y[:25000]\n",
    "    X = X[25000:]\n",
    "    Y = Y[25000:]\n",
    "    \n",
    "    net=torch.nn.Linear(d,2,bias=False)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "if dataset_name=='mnist-c':\n",
    "    import torchvision\n",
    "    trainset = torchvision.datasets.MNIST(\"./data/\",download=True,train=True)\n",
    "    testset = torchvision.datasets.MNIST(\"./data/\",download=True,train=False)\n",
    "    X = [torchvision.transforms.ToTensor()(s[0]) for s in trainset]\n",
    "    X = torch.cat(X).view(-1,28*28)\n",
    "    Y = torch.cat([torch.LongTensor([s[1]]) for s in trainset])\n",
    "    X_valid = [torchvision.transforms.ToTensor()(s[0]) for s in testset]\n",
    "    X_valid = torch.cat(X_valid).view(-1,28*28)\n",
    "    Y_valid = torch.cat([torch.LongTensor([s[1]]) for s in testset])\n",
    "    #torch.cat([torch.LongTensor([s[1]]) for s in testset])\n",
    "    n = 60000\n",
    "    net = models.OneHiddenLayer(nonlinearity_hidden=torch.nn.Softplus(),nonlinearity_out=torch.nn.Sigmoid(),d_in=28*28,d_hidden=100,d_out=10)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "if dataset_name=='mnist-a':\n",
    "    import torchvision\n",
    "    trainset = torchvision.datasets.MNIST(\"./data/\",download=True,train=True)\n",
    "    testset = torchvision.datasets.MNIST(\"./data/\",download=True,train=False)\n",
    "    X = [torchvision.transforms.ToTensor()(s[0]) for s in trainset]\n",
    "    X = torch.cat(X).view(-1,28*28)\n",
    "    Y = X\n",
    "    X_valid = [torchvision.transforms.ToTensor()(s[0]) for s in testset]\n",
    "    X_valid = torch.cat(X_valid).view(-1,28*28)\n",
    "    Y_valid = X_valid\n",
    "    n = len(trainset)\n",
    "    net = models.MNISTAutoencoder()\n",
    "    loss = lambda output,Y:torch.mean((output-Y)**2)#torch.nn.MSELoss has a bug for float on cpu\n",
    "    \n",
    "if dataset_name=='cifar-c':\n",
    "    import torchvision\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "    n = len(trainset)\n",
    "    X = [None]*len(trainset)\n",
    "    Y = [None]*len(trainset)\n",
    "    for i in range(len(trainset)):\n",
    "        (picture,label) = trainset[i]\n",
    "        X[i] = torchvision.transforms.ToTensor()(picture)\n",
    "        Y[i] = torch.LongTensor([label])\n",
    "    X = torch.cat(X).view(-1,3,32,32)\n",
    "    tmp = [torch.LongTensor([s[1]]) for s in trainset]\n",
    "    Y = torch.cat(tmp)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True)\n",
    "    X_valid = [torchvision.transforms.ToTensor()(s[0]) for s in testset]\n",
    "    X_valid = torch.cat(X_valid).view(-1,3,32,32)\n",
    "    Y_valid = torch.cat([torch.LongTensor([s[1]]) for s in testset])\n",
    "\n",
    "    net = models.CIFAR10WithSoftPlus()\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "import loss_functions\n",
    "wrapper = loss_functions.PyTorchWrapper(net, loss, l2_reg = 0.0, on_gpu=False)\n",
    "loss_computation = wrapper.forward\n",
    "gradient_computation = wrapper.gradient\n",
    "hessian_vector_computation = wrapper.Hv_store_gradient\n",
    "hessian_computation = wrapper.hessian\n",
    "finite_difference = False # False,'forward','central'/True\n",
    "\n",
    "if finite_difference:\n",
    "    delta_fd = 1e-6\n",
    "    if finite_difference == 'forward':\n",
    "        def fdHv(w,X,Y,v,**kwargs):\n",
    "            if wrapper.evaluate_gradient_for_hv:\n",
    "                mid = gradient_computation(w,X,Y,**kwargs)\n",
    "                wrapper.evaluate_gradient_for_hv = False\n",
    "            r = gradient_computation(w+delta_fd*v,X,Y,**kwargs)\n",
    "            return (r-mid)/delta_fd\n",
    "    else:\n",
    "        def fdHv(w,X,Y,v,**kwargs):\n",
    "            l = gradient_computation(w-delta_fd*v,X,Y,**kwargs)\n",
    "            r = gradient_computation(w+delta_fd*v,X,Y,**kwargs)\n",
    "            return (r-l)/(2*delta_fd)\n",
    "    hessian_vector_computation = fdHv\n",
    "\n",
    "\n",
    "d = wrapper.d\n",
    "w = X.new(d).zero_()\n",
    "\n",
    "TR=True\n",
    "SCR=True\n",
    "SGD=True\n",
    "\n",
    "def validation_loss(i,w,s):\n",
    "    validation_loss = wrapper.forward(w,X_valid,Y_valid)\n",
    "    print('Validation loss:',validation_loss)\n",
    "    if i==0:\n",
    "        s['validation_loss'] = []\n",
    "    s['validation_loss'].append(validation_loss)\n",
    "if SCR:\n",
    "    loss_collector=[]\n",
    "    timings_collector=[]\n",
    "    samples_collector=[]\n",
    "    \n",
    "    for k in range(n_runs): \n",
    "        SCR_loss=[]\n",
    "        SCR_x=[]\n",
    "        (w_SCR, _s)=scr.SCR(w,loss_computation,gradient_computation,\n",
    "                                                Hv=hessian_vector_computation,hessian=hessian_computation,\n",
    "                                                X=X, Y=Y, opt=opt_scr, **loss_args)\n",
    "        loss_collector.append(_s['loss'])\n",
    "        timings_collector.append(_s['time'])\n",
    "        samples_collector.append(_s['samples'])\n",
    "\n",
    "    SCR_loss = [float(sum(col))/len(col) for col in zip(*loss_collector)]\n",
    "    SCR_x = [float(sum(col))/len(col) for col in zip(*timings_collector)]    \n",
    "    SCR_samples= [float(sum(col))/len(col) for col in zip(*samples_collector)] \n",
    "if TR:\n",
    "    loss_collector=[]\n",
    "    timings_collector=[]\n",
    "    sampfles_collector=[]\n",
    "    for k in range(n_runs): \n",
    "        TR_loss=[]\n",
    "        TR_x=[]\n",
    "        (w_TR,_s)=tr.Trust_Region(w,loss_computation,gradient_computation,\n",
    "                                                      Hv=hessian_vector_computation, hessian=hessian_computation,\n",
    "                                                      X=X, Y=Y,opt=opt_tr, statistics_callback = validation_loss)\n",
    "        loss_collector.append(_s['loss'])\n",
    "        timings_collector.append(_s['time'])\n",
    "        samples_collector.append(_s['samples'])\n",
    "        \n",
    "    TR_loss = [float(sum(col))/len(col) for col in zip(*loss_collector)]\n",
    "    TR_x = [float(sum(col))/len(col) for col in zip(*timings_collector)]    \n",
    "    TR_samples= [float(sum(col))/len(col) for col in zip(*samples_collector)] \n",
    "    \n",
    "if SGD:\n",
    "    loss_collector=[]\n",
    "    timings_collector=[]\n",
    "    samples_collector=[]\n",
    "    \n",
    "    for k in range(n_runs): \n",
    "        SGD_loss=[]\n",
    "        SGD_x=[]\n",
    "        (w_SGD,_s)=gradient_methods.Gradient_Method(w,loss_computation,gradient_computation, X=X, Y=Y, opt=opt_sgd, statistics_callback = validation_loss)\n",
    "        loss_collector.append(_s['loss'])\n",
    "        timings_collector.append(_s['time'])\n",
    "        samples_collector.append(_s['samples'])\n",
    "\n",
    "    SGD_loss = [float(sum(col))/len(col) for col in zip(*loss_collector)]\n",
    "    SGD_x = [float(sum(col))/len(col) for col in zip(*timings_collector)]    \n",
    "    SGD_samples= [float(sum(col))/len(col) for col in zip(*samples_collector)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "show_plots(x_limits_time=(0,65))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_s['validation_loss']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
